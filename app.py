import streamlit as st 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.decomposition import PCA
from matplotlib.colors import ListedColormap
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler



url1 = "https://raw.githubusercontent.com/Kina03/ProjectIs/refs/heads/main/Global%20Peace%20Index%202023.csv"
data1 = pd.read_csv(url1)
url2 = "https://raw.githubusercontent.com/Kina03/ProjectIs/refs/heads/main/South_Asian_dataset.csv"
data2 = pd.read_csv(url2)


def page1():
    st.title("Machine Learning")
    st.header("About Datasets ðŸ“ˆðŸ“‘")
    st.write("ðŸ“„Dataset 1: Global Peace Index 2023ðŸ“‘")
    st.write("à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ 'Global Peace Index 2023' à¸›à¸£à¸°à¸à¸­à¸šà¸”à¹‰à¸§à¸¢à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸£à¸§à¸šà¸£à¸§à¸¡à¸ˆà¸²à¸à¸ªà¸–à¸²à¸šà¸±à¸™à¹€à¸¨à¸£à¸©à¸à¸¨à¸²à¸ªà¸•à¸£à¹Œà¹à¸¥à¸°à¸ªà¸±à¸™à¸•à¸´à¸ à¸²à¸ž (IEP) à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸à¸±à¸šà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸‚à¸­à¸‡à¸ªà¸±à¸™à¸•à¸´à¸ à¸²à¸ž ")
    
    st.text("Example features of Global Peace Index 2023 in dataset ")
    st.write(data1.head())

    st.markdown("""
    ðŸ” Source : [Global Peace Index 2023](https://www.kaggle.com/datasets/ddosad/global-peace-index-2023/data)
    ### Features of dataset :
    - Country : à¸Šà¸·à¹ˆà¸­à¸›à¸£à¸°à¹€à¸—à¸¨
    - iso3c : à¸£à¸«à¸±à¸ªà¸›à¸£à¸°à¹€à¸—à¸¨à¹à¸šà¸š 3 à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£
    - Overall Scores : à¸„à¸°à¹à¸™à¸™à¸£à¸§à¸¡
    - Safety and Security : à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¸„à¸‡
    - Ongoing Conflict : à¸„à¸§à¸²à¸¡à¸‚à¸±à¸”à¹à¸¢à¹‰à¸‡à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸„à¸‡à¸”à¸³à¹€à¸™à¸´à¸™à¸­à¸¢à¸¹à¹ˆ
    - Militarian : à¸£à¸°à¸”à¸±à¸šà¸‚à¸­à¸‡à¸à¸²à¸£à¸—à¸«à¸²à¸£
    """)       

    st.header("ðŸ‘©ðŸ»â€ðŸ’» Data preparation :")
    st.markdown("""
    - à¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œ CSV 
    - à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸› (NaN) à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ df.isnull().sum() à¹à¸¥à¸°à¸—à¸³à¸à¸²à¸£à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¹€à¸›à¹‡à¸™ NaN à¹ƒà¸™ Overall Scores à¸­à¸­à¸à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¸žà¸£à¹‰à¸­à¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ
    - à¹€à¸¥à¸·à¸­à¸à¹€à¸‰à¸žà¸²à¸°à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ à¹‚à¸”à¸¢ dataset à¹à¸£à¸ à¸ˆà¸°à¹ƒà¸Šà¹‰à¹à¸„à¹ˆà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'Overall Scores', 'Safety and Security', 'Ongoing Conflict'
    - à¸ªà¸£à¹‰à¸²à¸‡ Label (Target Variable)à¸Šà¸·à¹ˆà¸­à¸§à¹ˆà¸² Score Category à¸ªà¸³à¸«à¸£à¸±à¸š Classification à¹‚à¸”à¸¢à¸ˆà¸°à¹à¸šà¹ˆà¸‡ Overall Scores à¸­à¸­à¸à¹€à¸›à¹‡à¸™ 3 à¸à¸¥à¸¸à¹ˆà¸¡ à¹„à¸”à¹‰à¹à¸à¹ˆ 'Low'(à¸„à¸§à¸²à¸¡à¸ªà¸‡à¸šà¸•à¹ˆà¸³), 'Medium'(à¸„à¸§à¸²à¸¡à¸ªà¸‡à¸šà¸›à¸²à¸™à¸à¸¥à¸²à¸‡), 'High'(à¸„à¸§à¸²à¸¡à¸ªà¸‡à¸šà¸ªà¸¹à¸‡)
    - à¹à¸›à¸¥à¸‡ Label à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ LabelEncoder() à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸„à¹ˆà¸² 'Low', 'Medium', 'High' à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚ 0, 1, 2
    - à¸—à¸³à¸à¸²à¸£à¹à¸¢à¸à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ Features(X) â–¶ï¸ 'Safety and Security', 'Ongoing Conflict' à¹à¸¥à¸° Labels(y) â–¶ï¸ 'Score Category'(0, 1, 2) à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™à¸Šà¸¸à¸” Train/Test à¹‚à¸”à¸¢à¸ˆà¸°à¹à¸šà¹ˆà¸‡ Train = 80% à¹à¸¥à¸° Test = 20%
    - à¹ƒà¸Šà¹‰ Standardization à¹€à¸žà¸·à¹ˆà¸­à¸›à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸¡à¸²à¸•à¸£à¸à¸²à¸™ à¹‚à¸”à¸¢à¸—à¸³à¹ƒà¸«à¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¡à¸µà¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¹€à¸—à¹ˆà¸²à¸à¸±à¸š 0 à¹à¸¥à¸°à¸ªà¹ˆà¸§à¸™à¹€à¸šà¸µà¹ˆà¸¢à¸‡à¹€à¸šà¸™à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¹€à¸—à¹ˆà¸²à¸à¸±à¸š 1

""")

    st.header("ðŸ› ï¸ à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸² Model Machine Learning")
    st.markdown("""
    - **KNeighbors Classifier :**
        * KNN à¹€à¸›à¹‡à¸™à¹‚à¸¡à¹€à¸”à¸¥ Machine Learning à¸›à¸£à¸°à¹€à¸ à¸— Supervised à¹à¸šà¸š Classification à¸ˆà¸³à¹€à¸›à¹‡à¸™à¸•à¹‰à¸­à¸‡à¸¡à¸µ Data set à¸—à¸µà¹ˆà¸¡à¸µà¹€à¸‰à¸¥à¸¢(Label) à¸”à¹‰à¸§à¸¢ à¹‚à¸”à¸¢à¸­à¸²à¸¨à¸±à¸¢à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸‚à¸­à¸‡à¸£à¸°à¸¢à¸°à¸«à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸à¸²à¸£à¸ˆà¸³à¹à¸™à¸à¸›à¸£à¸°à¹€à¸ à¸— à¹‚à¸”à¸¢à¹€à¸£à¸²à¸ˆà¸°à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Global Peace Index 2023 à¹€à¸žà¸·à¹ˆà¸­à¸ˆà¸³à¹à¸™à¸à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸‡à¸šà¸ªà¸¸à¸‚à¸‚à¸­à¸‡à¸›à¸£à¸°à¹€à¸—à¸¨à¸•à¹ˆà¸²à¸‡ à¹† à¸­à¸­à¸à¹€à¸›à¹‡à¸™ 3 à¸à¸¥à¸¸à¹ˆà¸¡ à¸¡à¸µà¸à¸²à¸£à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ 
                à¹à¸¥à¸°à¹ƒà¸Šà¹‰ PCA à¹€à¸žà¸·à¹ˆà¸­à¸¥à¸”à¸¡à¸´à¸•à¸´à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸à¹ˆà¸­à¸™à¸—à¸µà¹ˆà¸ˆà¸°à¸™à¸³à¹„à¸›à¸à¸¶à¸à¹à¸¥à¸°à¸—à¸”à¸ªà¸­à¸šà¹‚à¸¡à¹€à¸”à¸¥ à¸‹à¸¶à¹ˆà¸‡à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¸ˆà¸³à¹à¸™à¸à¸›à¸£à¸°à¹€à¸—à¸¨à¸•à¸²à¸¡à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸‡à¸šà¸ªà¸¸à¸‚à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž à¹à¸¥à¸°à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸œà¹ˆà¸²à¸™ Accuracy Score à¹à¸¥à¸° Confusion Matrix à¸¡à¸µà¸à¸²à¸£à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¹€à¸›à¹‡à¸™à¸à¸£à¸²à¸Ÿ Scatter plot à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸«à¹‡à¸™à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸–à¸¹à¸à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£ à¹à¸¥à¸°à¸ˆà¸¸à¸”à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¹„à¸«à¸™ 
        * à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²
            * à¸—à¸³à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹à¸¥à¸°à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
            * à¹‚à¸¡à¹€à¸”à¸¥ KNeighbors Classifier à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¸¶à¹‰à¸™à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ KNeighborsClassifier(n_neighbors=5) à¹ƒà¸Šà¹‰à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸‚à¸­à¸‡à¸žà¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œ k à¹€à¸—à¹ˆà¸²à¸à¸±à¸š 5 à¹‚à¸”à¸¢à¹‚à¸¡à¹€à¸”à¸¥à¸ˆà¸°à¸—à¸³à¸à¸²à¸£à¸à¸¶à¸à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ X_train à¹à¸¥à¸° y_train à¹‚à¸”à¸¢à¸­à¸²à¸¨à¸±à¸¢à¸£à¸°à¸¢à¸°à¸«à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸žà¸·à¹ˆà¸­à¸à¸³à¸«à¸™à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¹à¸¢à¸à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
            * à¹ƒà¸Šà¹‰ train_test_split à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ 80% à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸ (Training Set) à¹à¸¥à¸° 20% à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸”à¸ªà¸­à¸š (Testing Set) à¹‚à¸”à¸¢à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² stratify=y à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¸§à¹ˆà¸²à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸‚à¸­à¸‡à¸à¸¥à¸¸à¹ˆà¸¡à¸¢à¸±à¸‡à¸„à¸‡à¸ªà¸¡à¸”à¸¸à¸¥à¸à¸±à¸™à¹ƒà¸™à¸Šà¸¸à¸” Train à¹à¸¥à¸° Test
            * à¹€à¸¡à¸·à¹ˆà¸­à¹‚à¸¡à¹€à¸”à¸¥à¹„à¸”à¹‰à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¶à¸à¹à¸¥à¹‰à¸§ à¸ˆà¸°à¹ƒà¸Šà¹‰à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸”à¸ªà¸­à¸š X_test à¹ƒà¸™à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢ à¹‚à¸”à¸¢à¹‚à¸¡à¹€à¸”à¸¥à¸ˆà¸°à¸—à¸³à¸™à¸²à¸¢à¸§à¹ˆà¸²à¸›à¸£à¸°à¹€à¸—à¸¨à¹„à¸«à¸™à¸„à¸§à¸£à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸à¸¥à¸¸à¹ˆà¸¡ Low, Medium à¸«à¸£à¸·à¸­ High à¸•à¸²à¸¡à¸¥à¸±à¸à¸©à¸“à¸°à¸‚à¸­à¸‡à¸•à¸±à¸§à¹à¸›à¸£ 'Safety and Security' à¹à¸¥à¸° 'Ongoing Conflict'
            * à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸”à¹‰à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¥à¹‰à¸§ à¸ˆà¸°à¸¡à¸µà¸à¸²à¸£à¹ƒà¸Šà¹‰ Accuracy Score à¹à¸¥à¸° Confusion Matrix à¹€à¸žà¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥
            * à¸¡à¸µà¸à¸²à¸£à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¹€à¸›à¹‡à¸™à¸à¸£à¸²à¸Ÿ Scatter plot à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸«à¹‡à¸™à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸–à¸¹à¸à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£ à¹à¸¥à¸°à¸ˆà¸¸à¸”à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¹„à¸«à¸™ 
                

    - **SVM Classifier :**
        * SVM à¸«à¸£à¸·à¸­ Support Vector Machine à¹€à¸›à¹‡à¸™à¹‚à¸¡à¹€à¸”à¸¥ Machine Learning à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸ˆà¸³à¹à¸™à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥(Classification) à¸«à¸£à¸·à¸­à¹à¸šà¹ˆà¸‡à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹‚à¸”à¸¢à¸ˆà¸°à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¹‰à¸™à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹à¸šà¹ˆà¸‡à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (Hyperplane) à¹à¸¥à¸°à¸«à¸²à¹€à¸ªà¹‰à¸™à¸—à¸²à¸‡à¸—à¸µà¹ˆà¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸” 
                à¹‚à¸¡à¹€à¸”à¸¥ SVM à¹„à¸”à¹‰à¸£à¸±à¸šà¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸‚à¸­à¸‡ KNeighbors Classifier à¹à¸¥à¸°à¸¡à¸µà¸à¸²à¸£à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸œà¹ˆà¸²à¸™ Accuracy Score à¹à¸¥à¸° Confusion Matrix
        * à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²
            * à¸—à¸³à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹à¸¥à¸°à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
            * à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥ SVM à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ SVC à¸‹à¸¶à¹ˆà¸‡à¹€à¸›à¹‡à¸™à¸„à¸¥à¸²à¸ªà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸šà¸ˆà¸³à¹à¸™à¸à¸›à¸£à¸°à¹€à¸ à¸— à¹à¸¥à¸°à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸žà¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œ random_state=42 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸³à¸‹à¹‰à¸³à¹„à¸”à¹‰ à¹à¸¥à¸°à¹ƒà¸Šà¹‰à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸‚à¸­à¸‡à¸žà¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œ (Kernel = 'rbf')
            * à¹ƒà¸Šà¹‰ train_test_split à¹€à¸žà¸·à¹ˆà¸­à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸­à¸à¹€à¸›à¹‡à¸™ 2 à¸ªà¹ˆà¸§à¸™ à¸„à¸·à¸­ 
                * 1. X_train à¹à¸¥à¸° X_test â–¶ï¸ à¹€à¸›à¹‡à¸™à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸à¸¶à¸à¹à¸¥à¸°à¸—à¸à¸ªà¸­à¸šà¹‚à¸¡à¹€à¸”à¸¥ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸•à¸±à¸§à¹à¸›à¸£ 'Safety and Security' à¹à¸¥à¸° 'Ongoing Conflict' 
                * 2. y_train à¹à¸¥à¸° y_test â–¶ï¸ à¸„à¸·à¸­à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹ƒà¸™à¸à¸²à¸£à¸ˆà¸³à¹à¸™à¸à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥ à¸¡à¸µà¸à¸²à¸£à¹ƒà¸Šà¹‰ stratify=y à¹€à¸žà¸·à¹ˆà¸­à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸•à¹ˆà¸¥à¸°à¸à¸¥à¸¸à¹ˆà¸¡à¸¡à¸µà¸ªà¸±à¸”à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆà¹€à¸—à¹ˆà¸²à¸à¸±à¸™
            * à¸à¹ˆà¸­à¸™à¸—à¸µà¹ˆà¸ˆà¸°à¸™à¸³à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸›à¹ƒà¸Šà¹‰à¸à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥ à¸ˆà¸°à¸•à¹‰à¸­à¸‡à¸¡à¸µà¸à¸²à¸£à¸—à¸³ Standardization à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ StandardScaler à¹€à¸žà¸·à¹ˆà¸­à¸—à¸³à¹ƒà¸«à¹‰à¸„à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ à¸¡à¸µà¸à¸²à¸£à¹ƒà¸Šà¹‰ fit_transform à¸à¸±à¸š X_train à¹à¸¥à¸° transform à¸à¸±à¸š X_test à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸Šà¸¸à¸”à¹ƒà¸Šà¹‰à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™
            * à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸”à¹‰à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹à¸¥à¹‰à¸§ à¸ˆà¸°à¸¡à¸µà¸à¸²à¸£à¹ƒà¸Šà¹‰ Accuracy Score à¹à¸¥à¸° Confusion Matrix à¹€à¸žà¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥ à¸¡à¸µà¸à¸²à¸£à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¹€à¸›à¹‡à¸™à¸à¸£à¸²à¸Ÿ Scatter plot à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸«à¹‡à¸™à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸–à¸¹à¸à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£ à¹à¸¥à¸°à¸ˆà¸¸à¸”à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¹„à¸«à¸™ 
            * à¸¡à¸µà¸à¸²à¸£à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¹€à¸›à¹‡à¸™à¸à¸£à¸²à¸Ÿ Scatter plot à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸«à¹‡à¸™à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸–à¸¹à¸à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£ à¹à¸¥à¸°à¸ˆà¸¸à¸”à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¹„à¸«à¸™ 
                

    - **KMeans :**
        * KMeans à¹€à¸›à¹‡à¸™ Unsupervised Learning à¸„à¸·à¸­à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹à¸šà¸šà¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ªà¸­à¸™ à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸³à¸•à¸­à¸šà¸•à¸²à¸¢à¸•à¸±à¸§ à¹‚à¸”à¸¢à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¸«à¸¥à¸±à¸à¸‚à¸­à¸‡ K-means à¸„à¸·à¸­à¸à¸²à¸£à¹à¸šà¹ˆà¸‡à¸à¸¥à¸¸à¹ˆà¸¡ à¹à¸šà¸š Clustering à¸‹à¸¶à¹ˆà¸‡à¸à¸²à¸£à¹à¸šà¹ˆà¸‡à¸à¸¥à¸¸à¹ˆà¸¡à¹ƒà¸™à¸¥à¸±à¸à¸©à¸“à¸°à¸™à¸µà¹‰à¸ˆà¸°à¹ƒà¸Šà¹‰à¸žà¸·à¹‰à¸™à¸à¸²à¸™à¸—à¸²à¸‡à¸ªà¸–à¸´à¸•à¸´ à¸‹à¸¶à¹ˆà¸‡à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¸‚à¸­à¸‡ clustering à¸„à¸·à¸­à¸à¸²à¸£à¸ˆà¸±à¸šà¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µà¸¥à¸±à¸à¸©à¸“à¸°à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸à¸¥à¸¸à¹ˆà¸¡à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™
        * à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²
            * à¸—à¸³à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹à¸¥à¸°à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
            * à¸—à¸³à¸à¸²à¸£à¸«à¸²à¸ˆà¸³à¸™à¸§à¸™ Cluster à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ Elbow Method à¸‹à¸¶à¹ˆà¸‡à¹€à¸›à¹‡à¸™à¹€à¸—à¸„à¸™à¸´à¸„à¸—à¸µà¹ˆà¸Šà¹ˆà¸§à¸¢à¸à¸³à¸«à¸™à¸” Cluster 
                à¹‚à¸”à¸¢à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸² WCSS à¸ªà¸³à¸«à¸£à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™ Cluster à¸—à¸µà¹ˆà¸•à¹ˆà¸²à¸‡à¸à¸±à¸™ à¹à¸¥à¸°à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¹€à¸žà¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¸¡à¸µà¸à¸²à¸£à¸¥à¸”à¸¥à¸‡à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¸‹à¸¶à¹ˆà¸‡à¸ˆà¸°à¹à¸ªà¸”à¸‡à¸ˆà¸³à¸™à¸§à¸™ Cluster à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡
            * à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸¥à¸·à¸­à¸à¸ˆà¸³à¸™à¸§à¸™ Cluster à¹à¸¥à¹‰à¸§à¹ƒà¸Šà¹‰ KMeans(n_clusters=3, random_state=42, n_init=10) à¹€à¸žà¸·à¹ˆà¸­à¸—à¸³à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸›à¸£à¸°à¹€à¸—à¸¨à¸­à¸­à¸à¹€à¸›à¹‡à¸™ 3 à¸à¸¥à¸¸à¹ˆà¸¡à¸•à¸²à¸¡à¸„à¹ˆà¸²à¸„à¸°à¹à¸™à¸™à¸—à¸µà¹ˆà¹„à¸”à¹‰
            *  à¸¡à¸µà¸à¸²à¸£à¸à¸³à¸«à¸¡à¸”à¸Šà¸·à¹ˆà¸­à¸à¸¥à¸¸à¹ˆà¸¡ Cluster à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸ˆà¸°à¸–à¸¹à¸à¸ˆà¸±à¸”à¸¥à¸³à¸”à¸±à¸šà¸•à¸²à¸¡à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡ "Overall Scores" à¹à¸¥à¸°à¸à¸³à¸«à¸™à¸”à¸Šà¸·à¹ˆà¸­à¸à¸¥à¸¸à¹ˆà¸¡ à¹„à¸”à¹‰à¹à¸à¹ˆ :
                * Highly Peaceful: à¸›à¸£à¸°à¹€à¸—à¸¨à¸—à¸µà¹ˆà¸¡à¸µà¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸‡à¸šà¸ªà¸¸à¸‚à¸ªà¸¹à¸‡à¸ªà¸¸à¸”
                * Moderately Peaceful: à¸›à¸£à¸°à¹€à¸—à¸¨à¸—à¸µà¹ˆà¸¡à¸µà¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸‡à¸šà¸ªà¸¸à¸‚à¸›à¸²à¸™à¸à¸¥à¸²à¸‡
                * High Conflict: à¸›à¸£à¸°à¹€à¸—à¸¨à¸—à¸µà¹ˆà¸¡à¸µà¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸‚à¸±à¸”à¹à¸¢à¹‰à¸‡à¸ªà¸¹à¸‡
            * à¸¡à¸µà¸à¸²à¸£à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸›à¸£à¸°à¹€à¸—à¸¨à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° Cluster à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ value_counts() à¹€à¸žà¸·à¹ˆà¸­à¸”à¸¹à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸±à¸§à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸° Cluster à¸§à¹ˆà¸²à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸¡à¸”à¸¸à¸¥à¸¡à¸±à¹‰à¸¢
            * à¸žà¸¥à¹‡à¸­à¸•à¸à¸£à¸²à¸Ÿà¹à¸ªà¸”à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ "Overall Scores" à¹à¸¥à¸° "Safety and Security" à¸žà¸£à¹‰à¸­à¸¡à¸à¸±à¸šà¸à¸²à¸£à¸£à¸°à¸šà¸²à¸¢à¸ªà¸µà¸•à¸²à¸¡à¸„à¸¥à¸±à¸ªà¹€à¸•à¸­à¸£à¹Œà¸—à¸µà¹ˆà¹‚à¸¡à¹€à¸”à¸¥à¹„à¸”à¹‰à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¹„à¸§à¹‰ à¸‹à¸¶à¹ˆà¸‡à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¹€à¸«à¹‡à¸™à¸ à¸²à¸žà¸£à¸§à¸¡à¸‚à¸­à¸‡à¸à¸¥à¸¸à¹ˆà¸¡à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸‚à¸¶à¹‰à¸™à¸ˆà¸²à¸à¸à¸²à¸£ Clustering
""")
        
                


def page2():

    st.title("Neural Network")
    st.header("About Datasets ðŸ“ˆðŸ“‘")
    st.write("ðŸ“„Dataset 2: South Asian Growth & Development Data (2000-23)ðŸ“‘")
    st.write("à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ 'South Asian Growth & Development Data (2000-23)' à¸›à¸£à¸°à¸à¸­à¸šà¸”à¹‰à¸§à¸¢à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ GDP à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¸§à¹ˆà¸²à¸‡à¸‡à¸²à¸™ à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¸£à¸¹à¹‰à¸«à¸™à¸±à¸‡à¸ªà¸·à¸­ à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸žà¸¥à¸±à¸‡à¸‡à¸²à¸™ à¸•à¸±à¸§à¸Šà¸µà¹‰à¸§à¸±à¸”à¸à¸²à¸£à¸à¸³à¸à¸±à¸šà¸”à¸¹à¹à¸¥ à¹à¸¥à¸°à¸­à¸·à¹ˆà¸™à¹† à¸‚à¸­à¸‡à¸›à¸£à¸°à¹€à¸—à¸¨à¹ƒà¸™à¹€à¸­à¹€à¸Šà¸µà¸¢à¹ƒà¸•à¹‰à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¸›à¸µ 2543 à¸–à¸¶à¸‡ 2566 à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸à¸²à¸£à¹€à¸•à¸´à¸šà¹‚à¸•à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸—à¸¨à¹„à¸”à¹‰")
    
    st.text("Example features of South Asian Growth & Development Data in dataset ")
    st.write(data2.head())    
    st.markdown("""
    ðŸ” Source : [South Asian Growth & Development Data (2000-23)](https://www.kaggle.com/datasets/rezwananik/south-asia-growth-and-development-data-2000-23)
    ### Features of dataset :
    - **Country :** à¸Šà¸·à¹ˆà¸­à¸›à¸£à¸°à¹€à¸—à¸¨
    - **Year :** à¸›à¸µ
    - **GDP (current US$) :** GDP (à¸”à¸­à¸¥à¸¥à¸²à¸£à¹Œà¸ªà¸«à¸£à¸±à¸à¹ƒà¸™à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™)
    - **GDP growth (annual %) :** à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¹€à¸•à¸´à¸šà¹‚à¸•à¸‚à¸­à¸‡ GDP (à¸£à¹‰à¸­à¸¢à¸¥à¸°à¸•à¹ˆà¸­à¸›à¸µ)
    - **GDP per capita (current US$) :** GDP à¸•à¹ˆà¸­à¸«à¸±à¸§ (à¸”à¸­à¸¥à¸¥à¸²à¸£à¹Œà¸ªà¸«à¸£à¸±à¸à¹ƒà¸™à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™)
    - **etc.**
    """)      


    st.header("ðŸ‘©ðŸ»â€ðŸ’» Data preparation :")
    st.markdown("""
    - à¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œ CSV 
    - à¹€à¸¥à¸·à¸­à¸à¹€à¸‰à¸žà¸²à¸°à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ à¹‚à¸”à¸¢ dataset à¸—à¸µà¹ˆà¸ªà¸­à¸‡ à¸ˆà¸°à¹ƒà¸Šà¹‰à¹à¸„à¹ˆà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'Country','Year', 'GDP (current US$)'
    - à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ ".." à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ NaN
    - à¹à¸›à¸¥à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'GDP (current US)' à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¸”à¹‰à¸§à¸¢ pd.to_numeric(df_selected["GDP (current US$)"], errors="coerce")
    - à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸› (NaN) à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ df.isnull().sum() à¹à¸¥à¸°à¸—à¸³à¸à¸²à¸£à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¹€à¸›à¹‡à¸™ NaN à¹ƒà¸™ GDP (current US$) à¸­à¸­à¸à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¸žà¸£à¹‰à¸­à¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸‹à¹‰à¸³à¸à¸±à¸™à¸”à¹‰à¸§à¸¢ drop_duplicates() à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹à¸™à¹ˆà¹ƒà¸ˆà¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸œà¸´à¸”à¸žà¸¥à¸²à¸” à¹ƒà¸Šà¹‰ Interpolation (df.interpolate()) à¹€à¸žà¸·à¹ˆà¸­à¹€à¸•à¸´à¸¡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸›à¹à¸šà¸šà¹€à¸ªà¹‰à¸™à¸•à¸£à¸‡
            à¸à¸£à¸­à¸‡à¸„à¹ˆà¸²à¸œà¸´à¸”à¸›à¸à¸•à¸´ (Outliers) à¸”à¹‰à¸§à¸¢ IQR (Interquartile Range) à¹€à¸žà¸·à¹ˆà¸­à¸¥à¸šà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸ˆà¸²à¸à¸„à¹ˆà¸²à¸›à¸à¸•à¸´à¸¡à¸²à¸à¹€à¸à¸´à¸™à¹„à¸›
    - à¹ƒà¸Šà¹‰ MinMaxScaler à¹€à¸žà¸·à¹ˆà¸­à¸›à¸£à¸±à¸šà¸„à¹ˆà¸² GDP (current US$) à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸Šà¹ˆà¸§à¸‡ 0-1 à¹€à¸žà¸·à¹ˆà¸­à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹„à¸”à¹‰à¸”à¸µà¸‚à¸¶à¹‰à¸™
    - à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³ LSTM à¹‚à¸”à¸¢à¸ˆà¸°à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¢à¹‰à¸­à¸™à¸«à¸¥à¸±à¸‡ 3 à¸›à¸µà¸—à¸µà¹ˆà¸œà¹ˆà¸²à¸™à¸¡à¸² à¹€à¸žà¸·à¹ˆà¸­à¸¡à¸²à¸—à¸³à¸™à¸²à¸¢ GDP à¹ƒà¸™à¸›à¸µà¸–à¸±à¸” à¹† à¹„à¸›

""")
    
    st.header("ðŸ› ï¸ à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸² Model Neural Network")
    st.markdown("""
    - **LSTM Neural Network :**
        * LSTM  à¹€à¸›à¹‡à¸™à¸›à¸£à¸°à¹€à¸ à¸—à¸«à¸™à¸¶à¹ˆà¸‡à¸‚à¸­à¸‡ Recurrent Neural Network (RNN) à¸–à¸¹à¸à¸­à¸­à¸à¹à¸šà¸šà¹ƒà¸«à¹‰à¸ˆà¸”à¸ˆà¸³ Patterns à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸™à¸²à¸™ à¹† à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¹ƒà¸™à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¹à¸šà¸š Sequential  à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²à¹à¸¥à¸°à¸™à¸³à¸¡à¸²à¹ƒà¸Šà¹‰à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹„à¸”à¹‰
        * à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²
            * à¸—à¸³à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹à¸¥à¸°à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
            * à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸¥à¸³à¸”à¸±à¸šà¹€à¸§à¸¥à¸² (Sequence Data) à¹‚à¸”à¸¢à¸ˆà¸°à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¢à¹‰à¸­à¸™à¸«à¸¥à¸±à¸‡ 3 à¸›à¸µ(SEQ_LENGTH = 3) à¹€à¸žà¸·à¹ˆà¸­à¹€à¸›à¹‡à¸™à¸­à¸´à¸™à¸žà¸¸à¸• à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥ à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸­à¸à¹€à¸›à¹‡à¸™
                * 1. X â–¶ï¸ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¢à¹‰à¸­à¸™à¸«à¸¥à¸±à¸‡ 3 à¸›à¸µ
                * 2. y â–¶ï¸ GDP à¸‚à¸­à¸‡à¸›à¸µà¸–à¸±à¸”à¹„à¸›à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢
            * à¹ƒà¸Šà¹‰ Interquartile Range (IQR) Method à¹€à¸žà¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹à¸¥à¸°à¸¥à¸šà¸„à¹ˆà¸²à¸œà¸´à¸”à¸›à¸à¸•à¸´ (outliers) à¸­à¸­à¸à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ GDP à¸‚à¸­à¸‡à¸›à¸£à¸°à¹€à¸—à¸¨
            * à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ 80% à¸ªà¸³à¸«à¸£à¸±à¸š Train à¹à¸¥à¸° 20% à¸ªà¸³à¸«à¸£à¸±à¸š Test à¹ƒà¸Šà¹‰ Train set à¹ƒà¸™à¸à¸²à¸£à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥ à¹à¸¥à¸°à¹ƒà¸Šà¹‰ Test set à¹€à¸žà¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥
            * à¹ƒà¸Šà¹‰à¹‚à¸„à¸£à¸‡à¸‚à¹ˆà¸²à¸¢à¸›à¸£à¸°à¸ªà¸²à¸—à¹€à¸—à¸µà¸¢à¸¡à¹à¸šà¸š LSTM (Long Short-Term Memory)  à¹‚à¸”à¸¢
                * LSTM Layer 1 à¸¡à¸µ 50 Neurons à¹à¸¥à¸°à¹ƒà¸Šà¹‰ relu à¹€à¸›à¹‡à¸™ activation function
                * LSTM Layer 2 à¸¡à¸µ 50 Neurons à¹à¸¥à¸°à¹ƒà¸Šà¹‰ relu à¹€à¸›à¹‡à¸™ activation function
                * Dense Layer (Fully Connected Layer): à¹ƒà¸Šà¹‰à¹€à¸›à¹‡à¸™ output layer à¸—à¸µà¹ˆà¸¡à¸µ 1 Neuron
                * à¹ƒà¸Šà¹‰ Adam Optimizer à¹à¸¥à¸° Mean Squared Error (MSE) à¹€à¸›à¹‡à¸™ loss function
            * à¸à¸³à¸«à¸™à¸”à¹ƒà¸«à¹‰à¸¡à¸µ 100 epochs à¹à¸¥à¸°à¹ƒà¸Šà¹‰ batch size = 8 à¹ƒà¸Šà¹‰à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸¶à¸à¸ªà¸­à¸™ (X_train, y_train) à¹à¸¥à¸°à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸”à¹‰à¸§à¸¢à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸”à¸ªà¸­à¸š (X_test, y_test)
            * à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢ GDP à¸‚à¸­à¸‡à¸­à¸™à¸²à¸„à¸•
                * à¹ƒà¸Šà¹‰à¸„à¹ˆà¸² GDP à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¹€à¸›à¹‡à¸™à¸ˆà¸¸à¸”à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™
                * à¸„à¸³à¸™à¸§à¸“ GDP à¸‚à¸­à¸‡à¸›à¸µà¸–à¸±à¸”à¹„à¸›à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¹‚à¸¡à¹€à¸”à¸¥ LSTM 
""")
    

def page3():

    st.title("Machine Learning Demo")
    st.header("ðŸŒ Global Peace Index Classification and Clustering")

    @st.cache_data
    def load_data():
        url = "https://raw.githubusercontent.com/Kina03/ProjectIs/refs/heads/main/Global%20Peace%20Index%202023.csv"
        df = pd.read_csv(url)
        df['Overall Scores'].fillna(df['Overall Scores'].mean(), inplace=True)
        return df
    df = load_data()

    #à¹€à¸¥à¸·à¸­à¸à¸›à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£
    year_list = sorted(df["year"].unique(), reverse=True)
    selected_year = st.selectbox("à¹€à¸¥à¸·à¸­à¸à¸›à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸”à¸¹à¸‚à¹‰à¸­à¸¡à¸¹à¸¥:", year_list)

    df_selected = df[df["year"] == selected_year].copy().reset_index(drop=True)

    # à¸ªà¸£à¹‰à¸²à¸‡ Label Encoding à¸ªà¸³à¸«à¸£à¸±à¸š Score Category
    df_selected['Score Category'] = pd.qcut(df_selected['Overall Scores'], q=3, labels=['Low', 'Medium', 'High'])
    df_selected['Score Category'] = LabelEncoder().fit_transform(df_selected['Score Category'])

    # à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š Classification
    X = df_selected[['Safety and Security', 'Ongoing Conflict']]
    y = df_selected['Score Category']

    if len(y.unique()) > 1:
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
        scaler = StandardScaler()
        X_train, X_test = scaler.fit_transform(X_train), scaler.transform(X_test)

        # Train à¹à¸¥à¸° à¹à¸ªà¸”à¸‡à¸œà¸¥
        def train_and_plot(model, name):
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)

            st.subheader(f"{name} Model Performance for Year {selected_year}")
            st.write(f"âœ… **Accuracy:** {accuracy:.2f}")

            # à¹à¸ªà¸”à¸‡ Confusion Matrix
            st.write(f"ðŸ“Š **Confusion Matrix ({name}):**")
            st.write(pd.DataFrame(confusion_matrix(y_test, y_pred),
                                index=['Actual Low', 'Actual Medium', 'Actual High'],
                                columns=['Pred Low', 'Pred Medium', 'Pred High']))

            # à¸ªà¸£à¹‰à¸²à¸‡ Scatter Plot
            cmap = ListedColormap(['Tomato', 'PaleGreen', 'Gold'])
            fig, ax = plt.subplots(figsize=(8, 6))
            scatter = ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cmap, alpha=0.6, s=90)

            # à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¸œà¸´à¸”
            incorrect_indices = np.where(y_pred != y_test)[0]
            ax.scatter(X_test[incorrect_indices, 0], X_test[incorrect_indices, 1], 
                    marker='x', color='RoyalBlue', label='Misclassified', s=100)

            #à¸Šà¸·à¹ˆà¸­à¸›à¸£à¸°à¹€à¸—à¸¨
            country_test = df_selected.iloc[X_test.shape[0]:]["Country"].values
            num_points = min(len(X_test), len(country_test))
            for i in range(num_points):
                ax.annotate(country_test[i], (X_test[i, 0], X_test[i, 1]), textcoords="offset points",
                            xytext=(0, 10), ha='center', fontsize=6)

            plt.title(f'{name} Predictions for Year {selected_year} with Misclassified Points')
            plt.xlabel('Safety and Security')
            plt.ylabel('Ongoing Conflict')

            legend_elements = scatter.legend_elements()
            plt.legend(handles=legend_elements[0], labels=['Low', 'Medium', 'High'], loc="upper left", title="Peace Level")
            st.pyplot(fig)

        # Train à¹à¸¥à¸°à¹à¸ªà¸”à¸‡à¸œà¸¥ 
        train_and_plot(KNeighborsClassifier(n_neighbors=5), "KNN")
        train_and_plot(SVC(kernel='rbf', random_state=42), "SVM")

    # à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š Clustering
    features = ["Overall Scores", "Safety and Security", "Ongoing Conflict", "Militarian"]
    df_clean = df.dropna(subset=["Overall Scores"]).copy()  # à¸¥à¸šà¸„à¹ˆà¸² NaN

    scaler = StandardScaler()
    df_cluster_scaled = scaler.fit_transform(df_clean[features])

    #à¹ƒà¸Šà¹‰ Elbow Method à¸«à¸² K à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡
    wcss = []
    K_range = range(1, 11)
    for k in K_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(df_cluster_scaled)
        wcss.append(kmeans.inertia_)

    fig, ax = plt.subplots(figsize=(8, 5))
    ax.plot(K_range, wcss, marker='o', linestyle='--')
    ax.set_xlabel('Number of Clusters')
    ax.set_ylabel('WCSS')
    ax.set_title('Elbow Method to Determine Optimal K')
    st.pyplot(fig)

    # à¹ƒà¸Šà¹‰ K-Means à¹à¸šà¹ˆà¸‡à¹€à¸›à¹‡à¸™ 3 à¸à¸¥à¸¸à¹ˆà¸¡
    features = ["Overall Scores", "Safety and Security", "Ongoing Conflict", "Militarian"]
    df_cluster = df[df["year"] == selected_year].dropna(subset=["Overall Scores"]).copy()

    scaler = StandardScaler()
    df_cluster_scaled = scaler.fit_transform(df_cluster[features])

    st.subheader(f"KMeans Model Performance for Year {selected_year}")
    features = ["Overall Scores", "Safety and Security", "Ongoing Conflict", "Militarian"]
    df_cluster_scaled = StandardScaler().fit_transform(df_selected[features])

    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
    df_selected["Cluster"] = kmeans.fit_predict(df_cluster_scaled)

    cluster_order = df_selected.groupby("Cluster")["Overall Scores"].mean().sort_values().index.tolist()
    cluster_labels = {
        cluster_order[0]: "Highly Peaceful",  #à¸ªà¸‡à¸šà¸¡à¸²à¸
        cluster_order[1]: "Moderately Peaceful",
        cluster_order[2]: "High Conflict"  #à¸„à¸§à¸²à¸¡à¸‚à¸±à¸”à¹à¸¢à¹‰à¸‡à¸¡à¸²à¸
    }

    df_selected["Cluster Label"] = df_selected["Cluster"].map(cluster_labels)

    cluster_colors = {
        "Highly Peaceful": 'PaleGreen',
        "Moderately Peaceful": 'Gold',
        "High Conflict": 'Tomato'}

    # à¹€à¸¥à¸·à¸­à¸à¸›à¸£à¸°à¹€à¸—à¸¨
    selected_country = st.selectbox("ðŸŒ à¹€à¸¥à¸·à¸­à¸à¸›à¸£à¸°à¹€à¸—à¸¨ : ", df_selected["Country"].sort_values().unique())

    # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸£à¸°à¹€à¸—à¸¨à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸
    country_data = df_selected[df_selected["Country"] == selected_country]

    if not country_data.empty:
        cluster_label = country_data["Cluster Label"].values[0]
    
    if cluster_label == "Highly Peaceful":
        st.success(f"ðŸŒ± **{selected_country} à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸à¸¥à¸¸à¹ˆà¸¡:** {cluster_label}")
    elif cluster_label == "Moderately Peaceful":
        st.warning(f"ðŸŒž **{selected_country} à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸à¸¥à¸¸à¹ˆà¸¡:** {cluster_label}")
    else:
        st.error(f"âš”ï¸ **{selected_country} à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸à¸¥à¸¸à¹ˆà¸¡:** {cluster_label}") 

    #à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿ Scatter Plot
    cmap = ListedColormap([cluster_colors[cluster_labels[cluster_order[0]]],  # Highly Peaceful (à¹€à¸‚à¸µà¸¢à¸§)
                            cluster_colors[cluster_labels[cluster_order[1]]],  # Moderately Peaceful (à¹€à¸«à¸¥à¸·à¸­à¸‡)
                            cluster_colors[cluster_labels[cluster_order[2]]]])  # High Conflict (à¹à¸”à¸‡)

    fig, ax = plt.subplots(figsize=(8, 6))
    scatter = ax.scatter(df_selected["Overall Scores"],
                        df_selected["Safety and Security"],
                        c=df_selected["Cluster"].map(lambda x: cluster_order.index(x)),
                        cmap=cmap, alpha=0.6, s=90)

    ax.set_title("Clusters based on Overall Scores and Safety & Security")
    ax.set_xlabel("Overall Scores")
    ax.set_ylabel("Safety and Security")

    # à¹à¸ªà¸”à¸‡à¸›à¸£à¸°à¹€à¸—à¸¨à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸à¹ƒà¸™à¸à¸£à¸²à¸Ÿ
    if not country_data.empty:
        country_x = country_data["Overall Scores"].values[0]
        country_y = country_data["Safety and Security"].values[0]
        ax.scatter(country_x, country_y, color='SlateBlue', s=110, edgecolor='DarkSlateBlue', marker='o', label=selected_country)
        ax.annotate(selected_country, (country_x, country_y), textcoords="offset points", xytext=(0, 10), ha='center', fontsize=10, color='black')

    plt.legend(handles=scatter.legend_elements()[0], labels=["Highly Peaceful", "Moderately Peaceful", "High Conflict"], title="Cluster")
    st.pyplot(fig)

    # à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
    st.write("ðŸ“Œ **à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸£à¸°à¹€à¸—à¸¨à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸:**")
    st.dataframe(country_data[["Country", "Overall Scores", "Safety and Security", "Ongoing Conflict", "Cluster Label"]], use_container_width=True)

    st.write("ðŸ“Š **K-Means Clustering Results**")
    st.dataframe(df_selected[["Country", "Cluster Label"]].sort_values("Cluster Label"), use_container_width=True)


def page4():

    st.title("Neural Network Demo")
    st.header("ðŸ“‰ South Asian Growth & Development Data (2000-23)")
    url2 = "https://raw.githubusercontent.com/Kina03/ProjectIs/refs/heads/main/South_Asian_dataset.csv"
    data2 = pd.read_csv(url2)

    #à¹€à¸¥à¸·à¸­à¸à¸›à¸£à¸°à¹€à¸—à¸¨
    st.subheader(f"LSTM Neural Network")
    selected_country = st.selectbox("ðŸŒ à¹€à¸¥à¸·à¸­à¸à¸›à¸£à¸°à¹€à¸—à¸¨à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸”à¸¹ GDP :", data2["Country"].unique())

    # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¸­à¸‡à¸›à¸£à¸°à¹€à¸—à¸¨à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸
    df_country = data2[data2["Country"] == selected_country][["Year", "GDP (current US$)"]].dropna()
    df_country["GDP (current US$)"] = df_country["GDP (current US$)"].interpolate(method="linear")
    df_country = df_country.drop_duplicates(subset=["Year"], keep="first")

    # à¸¥à¸šà¸„à¹ˆà¸²à¸œà¸´à¸”à¸›à¸à¸•à¸´
    Q1 = df_country["GDP (current US$)"].quantile(0.25)
    Q3 = df_country["GDP (current US$)"].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_country = df_country[(df_country["GDP (current US$)"] >= lower_bound) & (df_country["GDP (current US$)"] <= upper_bound)]

    #Scaling à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
    scaler = MinMaxScaler(feature_range=(0, 1))
    df_country["GDP_scaled"] = scaler.fit_transform(df_country[["GDP (current US$)"]])

    #à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š LSTM
    SEQ_LENGTH = 3
    def create_sequences(data, seq_length):
        X, y = [], []
        for i in range(len(data) - seq_length):
            X.append(data[i : i + seq_length])
            y.append(data[i + seq_length])
        return np.array(X), np.array(y)

    data = df_country["GDP_scaled"].values
    X, y = create_sequences(data, SEQ_LENGTH)

    #à¹à¸šà¹ˆà¸‡ Train/Test Set
    split = int(len(X) * 0.8)
    X_train, y_train = X[:split], y[:split]
    X_test, y_test = X[split:], y[split:]

    #à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥ LSTM
    model = Sequential([
        LSTM(50, activation="relu", return_sequences=True, input_shape=(SEQ_LENGTH, 1)),
        LSTM(50, activation="relu"),
        Dense(1)
    ])
    model.compile(optimizer="adam", loss="mse")

    # à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥
    X_train = X_train.reshape(-1, SEQ_LENGTH, 1)
    X_test = X_test.reshape(-1, SEQ_LENGTH, 1)
    model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_test, y_test), verbose=0)

    # à¸—à¸³à¸™à¸²à¸¢ à¸ˆà¸™à¸–à¸¶à¸‡à¸›à¸µ 2030
    future_years = list(range(df_country["Year"].max() + 1, 2031))
    future_gdp_scaled = []
    last_sequence = X[-1].reshape(1, SEQ_LENGTH, 1)

    for year in future_years:
        next_gdp_scaled = model.predict(last_sequence)[0][0]
        future_gdp_scaled.append(next_gdp_scaled)
        last_sequence = np.roll(last_sequence, -1)
        last_sequence[0, -1, 0] = next_gdp_scaled

    future_gdp_actual = scaler.inverse_transform(np.array(future_gdp_scaled).reshape(-1, 1)).flatten()

    st.subheader(f"ðŸ”® à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢ GDP à¸‚à¸­à¸‡ {selected_country} à¸ˆà¸™à¸–à¸¶à¸‡à¸›à¸µ 2030")

    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(df_country["Year"], df_country["GDP (current US$)"], label="Actual GDP", marker="o")
    ax.plot(future_years, future_gdp_actual, label="Predicted GDP", marker="x", linestyle="dashed", color="red")
    ax.set_xlabel("Year")
    ax.set_ylabel("GDP (US$)")
    ax.legend()
    ax.set_title(f"GDP Forecast for {selected_country} until 2030")
    st.pyplot(fig)

    future_df = pd.DataFrame({"Year": future_years, "Predicted GDP": future_gdp_actual})
    st.dataframe(future_df, use_container_width=True)
 
pg = st.navigation([
    st.Page(page1, title="Machine Learning", icon="ðŸ¦¾"),
    st.Page(page2, title="Neural Network", icon="ðŸ§ "),
    st.Page(page3, title="Machine Learning Demo", icon="ðŸ¤–"),
    st.Page(page4, title="Neural Network Demo", icon="ðŸ§¬")
])
pg.run()